# YOLOv11n + SORT 实时行人追踪 (OpenVINO C++)

这是一个使用 C++ 和 OpenVINO 工具套件实现的实时多人行人追踪项目。项目采用 YOLOv11n 模型进行高效率的目标检测，并结合经典的 **SORT (Simple Online and Realtime Tracking)** 算法实现对检测到的行人进行持续的 ID 分配和轨迹追踪。

## 项目结构

```
makefile
├── include/
│   ├── Detector.hpp        # YOLO检测器封装
│   ├── Hungarian.hpp       # 匈牙利算法
│   ├── Sort.hpp            # SORT
│   └── Track.hpp           # 单个目标追踪轨迹（含卡尔曼滤波器）
├── model/
│   └── yolo11n.onnx        # YOLOv11n
├── src/
│   ├── Detector.cpp        # 检测器实现（预处理、推理、后处理）
│   ├── Hungarian.cpp       # 匈牙利算法实现
│   ├── IoU.cpp             # 计算交并比
│   ├── Sort.cpp            # SORT实现
│   ├── Track.cpp           # 追踪轨迹实现
│   └── main.cpp            # 主程序入口
├── video/
│   └── 003.avi             # 测试视频文件
└── CMakeLists.txt
```

## 环境配置与编译

### 1. 前置依赖

在编译前，请确保您的系统已安装以下依赖：

- **C++ 编译器**: 支持 C++17 的编译器 (如 GCC 8.0+)。
- **CMake**: 版本 3.10 或更高。
- **OpenCV**: 版本 4.5.4 或更高。
- **OpenVINO™ Tookit**: 2024.6 或更高

### 2. 编译步骤

使用标准的 CMake流程进行编译：

```bash
mkdir build && cd build
cmake ..
make
```

成功编译后，`build` 目录下会生成一个名为 `tracker` 的可执行文件。

## 如何运行

在 `build` 目录下执行以下命令：

```bash
./tracker
```

程序将自动加载 `../model/` 目录下的模型和 `../video/` 目录下的视频文件进行追踪，并实时显示结果。

## 代码流程解析

程序的执行流程遵循一个经典的“检测-追踪”范式：

1. **初始化 (main.cpp)**:

   创建 `Detector` 对象，加载 ONNX 模型并编译到指定设备（如 CPU）。

   创建 `SORTTracker` 对象，设置追踪参数（如 `max_age`, `min_hits`）。

   打开视频文件或摄像头。

2. **主循环 (main.cpp)**:

   从视频源逐帧读取图像 (`cv::Mat frame`)。

3. **检测阶段 (Detector::detect)**:

   **预处理**: 对输入帧执行 `letterbox` 操作，将其缩放并填充到模型所需的输入尺寸（如 640x640），同时保持原始宽高比。此过程会记录下缩放比例和填充值。

   **创建 Blob**: 使用 `cv::dnn::blobFromImage` 将 `letterbox` 后的图像转换为一个 NCHW 格式的 `blob`，并进行归一化（像素值除以 255.0）和颜色空间转换（BGR -> RGB）。

   **推理**: 将 `blob` 送入 OpenVINO 推理引擎，执行前向传播，得到原始输出张量（形状为 `[1, 84, 8400]`）。

   **后处理 (Detector::postprocess)**:
    a. **转置**: 将 `[1, 84, 8400]` 的输出转置为 `[8400, 84]`，使每个提议（proposal）的数据连续存储。
    b. **解码与过滤**: 遍历 8400 个提议，解析出边界框坐标、最高类别置信度和类别 ID。只保留类别为“行人”且置信度高于阈值的提议。
    c. **坐标还原**: 利用预处理时记录的缩放比例和填充值，将边界框坐标从 `letterbox` 空间精确地还原到原始视频帧的空间。
    d. **NMS**: 应用非极大值抑制（NMS）来合并同一目标的重叠检测框。

   `detect` 函数最终返回一个 `std::vector<Detection>`，其中包含了当前帧所有被检测到的行人的精确位置。

4. **追踪阶段 (SORTTracker::update)**:

   接收检测器返回的 `detections` 列表。

   **预测**: 对所有已存在的轨迹，使用卡尔曼滤波器预测其在当前帧的新位置。

   **关联**: 计算预测的轨迹框与当前帧的检测框之间的 IoU，并构建成本矩阵。使用匈牙利算法求解最优匹配。

   **更新**:

   ​	对于成功匹配的轨迹，使用新的检测框数据更新其卡尔曼滤波器状态。

   ​	对于未匹配的检测，创建为新的轨迹。

   ​	对于未匹配的轨迹，增加其“失踪”时间，超过 `max_age` 则删除。

   ​	`update` 函数最终返回一个 `std::vector<Track>`，其中包含了所有当前“活跃”且“可靠”的轨迹信息（ID 和位置）。

5. **可视化 (main.cpp)**:

   遍历追踪器返回的活跃轨迹，在原始帧上绘制边界框和追踪 ID。

   显示处理后的视频帧。

## 过程中遇到的问题

1. **坐标映射**

   最初版本的代码虽然能运行，但绘制出的边界框位置和大小完全错乱。

   **原因**: 在后处理阶段，用于还原坐标的缩放比例计算错误。预处理时使用了 `scale = min(模型尺寸/图像尺寸)`，而后处理时错误地计算了一个不相干的比例，导致无法正确还原。

   **结论**: **预处理和后处理必须是严格的逆运算**。传递或重新计算出与预处理完全一致的 `scale` 和 `padding` 值是坐标映射正确的唯一前提。

2. **过高置信度与负数坐标**

   程序输出的置信度是几百甚至上千的巨大数值，边界框坐标出现负数，类别检测结果更是牛头不对马嘴。

   **原因**: **模型输出张量的内存布局问题**。YOLOv11 输出形状为 `[1, 84, 8400]`，其数据是按通道连续存储的（即先存所有8400个 `cx`，再存所有 `cy`...）。

   **解决方案**: 在解析前，必须使用 `cv::transpose` 将 `[84, 8400]` 的数据矩阵**转置**为 `[8400, 84]` 的形式。这是处理此类模型输出的**标准操作**。

3. **OpenVINO的 `PrePostProcessor` (PPP) **

   为了追求更“现代”的 OpenVINO 2.0 写法，尝试使用 `ov::preprocess::PrePostProcessor` (PPP) 自动处理预处理，但遭遇了一系列崩溃和报错。

   **结论**: PPP 虽然强大，但其配置和数据流转方式有其特定规则。当出现难以调试的问题时，回归到 `letterbox` + `cv::dnn::blobFromImage` 更可控。

## 配置与调优

您可以在 `main.cpp` 的开头轻松调整以下关键参数：

- `conf_threshold`: 目标检测的置信度阈值。如果看不到任何检测框，首先应该尝试降低此值（例如从 `0.5f` 降到 `0.25f`）。
- `nms_threshold`: 非极大值抑制的 IoU 阈值。
- `max_age`: 一个轨迹在连续多少帧未被检测到后被删除。增加此值可以更好地处理短暂的遮挡。
- `min_hits`: 一个新轨迹需要连续多少帧被检测到才能被认为是“可靠的”并被显示。
- `iou_threshold`: SORT 算法中，用于判断一个检测和一个轨迹是否匹配的最小 IoU。